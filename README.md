# HGLMA

## Overview

```HGLMA``` is a HyperGraph Learning approach with Multi-dimensional metabolite feature extractions and static-dynamic Attention mechanisms for predicting missing reactions in genome-scale metabolic models (GEMs). For draft GEMs generated by automated reconstruction pipelines, HGLMA can be used to further conduct gap-fillings by predicting confidence scores of candidate metabolic reactions. 

HGLMA consists of three modules: the metabolite feature extraction module, hypergraph learning module, and attention mechanism module. The metabolite feature extraction module simultaneously uses two pre-trained language models to extract multi-dimensional metabolite features, and 1-dimensional (1D) and 2-dimensional (2D) embeddings are fused and regarded as node embeddings for further graph learning. The hypergraph learning module successively applies a directional graph network and a hypergraph neural network to extract the metabolite and topology features of GEMs. The attention mechanism module uses the static-dynamic multi-head attention mechanism to automatically align attention weights and to identify key metabolites within any candidate reaction, and finally output the confidence score of any candidate metabolite reaction as the missing reaction of a GEM.

The overall framework of HGLMA is shown in the following figure. 

![HGLMA](https://raw.githubusercontent.com/JiaJun-Q/HGLMA/main/HGLMA.jpg)

## Description
There are totally six folders, which are briefly described as below.   
- The folder ```Data``` contains the datasets for training and testing of HGLMA, and contains the summarized experimental results that are also available in the supplementary materials.
- The folder ```HGLMA_embeddings``` contains the codes for multi-dimensional metabolite feature extractions.
- The folder ```HGLMA_prediction``` contains the codes and corresponding files for the evaluation of reaction prediction performances. 
- The folder ```HGLMA_recovery``` contains the codes and corresponding files for the evaluation of reaction recovery.
- The folder ```HGLMA_ablation``` contains the codes and corresponding files for the ablation study.
- The folder ```HGLMA_gapfilling``` contains the codes and corresponding files for gap-fillings and metabolic phenotype predictions. 


## System Requirements

The proposed HGLMA has been implemented, trained, and tested by using ```Python 3.8``` and ```PyTorch 2.1.0``` with ```CUDA 12.1``` and an ```NVIDIA RTX4090``` graphics card.

The package depends on the Python scientific stack:

```
torch: 2.1.0
dgl: 2.4.0 + cu121
dhg: 0.9.5
numpy: 1.23.5
pandas: 1.1.1
cobra: 0.22.1
optlang: 1.5.2
python-libsbml: 5.19.0
networkx: 2.8.8
scipy: 1.10.1
scikit-learn: 0.23.1
matplotlib: 3.3.4
tqdm: 4.66.5
rdkit: 2022.3.5
node2vec: 0.4.6
openpyxl: 3.1.5
```

In addition, users are required to install the ```cplex``` solver (https://www.ibm.com/analytics/cplex-optimizer) from IBM to run the codes of gap-fillings. It is noted that cplex only works with certain python versions (e.g., CPLEX_Studio12.10 has APIs for python3.6 an python3.7).

## Usage

### Datasets 

- The folder ```Data/Dataset/BiGG dataset``` contains 108 BiGG GEMs, which are also available in other sources (xxxxxxxxxxxxxxxxxxxxx).
- The folder ```Data/Dataset/Taxonomy dataset``` contains 24 draft GEMs, where are generated by CarveMe from the 24 bacterial genomes (xxxxxxxxxxxxxxxxxxxxx).
- The folder ```Data/Dataset/Reaction pool``` contains the universal reaction pool, which is also available in other sources (xxxxxxxxxxxxxxxxxxxxx).

### Multi-dimensional Metabolite Feature Extractions 

- The codes are available in the folder ```HGLMA_embeddings```. We can extract multi-dimensional metabolite features from metabolite SMILES and molecular structures by using the pre-trained models ```ChemBERTa``` and ```GraphMVP```, respectively.
- The link to the pre-trained model ```ChemBERTa``` is as follows: https://huggingface.co/seyonec/ChemBERTa-zinc-base-v1
- The link to the pre-trained model ```GraphMVP``` is as follows: https://github.com/chao1224/GraphMVP
- For the running of other codes of training and testing HGLMA, we can download the embedding files for all metabolites **`metabolite_emb_2816.pkl`** ([download link](https://drive.google.com/file/d/1-21en06Ds1Bo11ljRYP-1qelxAb91QJb/view?usp=sharing)). 

### Evaluation of Reaction Prediction Performance

- The codes are available in the folder ```HGLMA_prediction``` for evaluting reaction prediction performances of HGLMA.
- We can run the script ```HGLMA_prediction/main.py``` to conduct 5-fold cross-validations of HGLMA on 108 GEMs. 
- The folder ```Data/Trained model/Trained_model (prediction)/iBWG_1329``` contains the trained HGLMA models for 5-fold cross-validations on iBWG_1329 (one of the 108 GEMs). 
- The evaluation results of prediction performances by HGLMA and baseline methods are summarized and available in ```Data/Evaluation of reaction prediction performances```.

### Evaluation of reaction recovery

- The codes are available in the folder ```HGLMA_prediction``` for evaluting reaction recovery performances of HGLMA.
-  


### Ablation Study

- The codes in the folders ```HGLMA_ablation/HGLMA - v1```, ```HGLMA_ablation/HGLMA - v2```, and ```HGLMA_ablation/HGLMA - v3``` correspond to three variants of HGLMA for the ablation study. 
- For instance, we can run the script ```HGLMA_ablation/HGLMA - v1/main.py``` to conduct 5-fold cross-validations  of the variant HGLMA-v1 on 108 GEMs.  
- The results of the ablation study are summarized and available in  ```Data/Ablation study```.

- If you wang to run ```HGLMA```, please download pre-trained node embedding files for all metabolites **`metabolite_emb_2816.pkl`** ([download link](https://drive.google.com/file/d/1-21en06Ds1Bo11ljRYP-1qelxAb91QJb/view?usp=sharing)) and place it in the `data` folder.
- To run the code, you need to navigate to the corresponding folder first, then type "python3 main.py" in your terminal.


### Prepare your input files

1. The folder ```HGLMA_gapfilling/BiGG Models``` contains 1 GEM from Zimmermann et al. as examples. GEM is a xml file.
2. The folder ```HGLMA_gapfilling/data/pools``` need to contain a reaction pool under name ```bigg_universe.xml```. Each pool is a GEM that has the extension ```.xml```. To use your own pool, remember to rename it to ```universe.xml```. Also remember to edit ```EX_SUFFIX``` and ```NAMESPACE``` in the input_parameters.txt to specify the suffix of exchange reactions and which namespace of biochemical reaction database is used. For ```NAMESPACE```, we currently only support ```bigg```.
