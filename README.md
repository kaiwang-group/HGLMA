# HGLMA

## Overview

```HGLMA``` is a HyperGraph Learning approach with Multi-dimensional metabolite feature extractions and static-dynamic Attention mechanisms for predicting missing reactions in genome-scale metabolic models (GEMs). For draft GEMs generated by automated reconstruction pipelines, HGLMA can be used to further conduct gap-fillings by predicting confidence scores of candidate metabolic reactions. 

HGLMA consists of three modules: the metabolite feature extraction module, hypergraph learning module, and attention mechanism module. The metabolite feature extraction module simultaneously uses two pre-trained language models to extract multi-dimensional metabolite features, and 1-dimensional (1D) and 2-dimensional (2D) embeddings are fused and regarded as node embeddings for further graph learning. The hypergraph learning module successively applies a directional graph network and a hypergraph neural network to extract the metabolite and topology features of GEMs. The attention mechanism module uses the static-dynamic multi-head attention mechanism to automatically align attention weights and to identify key metabolites within any candidate reaction, and finally output the confidence score of any candidate metabolite reaction as the missing reaction of a GEM.

The overall framework of HGLMA is shown in the following figure. 

![HGLMA](https://raw.githubusercontent.com/JiaJun-Q/HGLMA/main/HGLMA.jpg)

## Description
There are totally six folders, which are briefly described as below.   
- The folder ```Data``` contains the datasets for training and testing of HGLMA, and contains the summarized experimental results that are also available in the supplementary materials.
- The folder ```HGLMA_embeddings``` contains the script for multi-dimensional metabolite feature extractions.
- The folder ```HGLMA_prediction``` contains the scripts and corresponding files for the evaluation of reaction prediction performances. 
- The folder ```HGLMA_recovery``` contains the scripts and corresponding files for the evaluation of reaction recovery.
- The folder ```HGLMA_ablation``` contains the scripts and corresponding files for the ablation study.
- The folder ```HGLMA_gapfilling``` contains the scripts and corresponding files for gap-fillings and metabolic phenotype predictions. 


## System Requirements

The proposed HGLMA has been implemented, trained, and tested by using ```Python 3.8``` and ```PyTorch 2.1.0``` with ```CUDA 12.1``` and an ```NVIDIA RTX4090``` graphics card.

The package depends on the Python scientific stack:

```
torch: 2.1.0
dgl: 2.4.0 + cu121
dhg: 0.9.5
numpy: 1.23.5
pandas: 1.1.1
cobra: 0.22.1
optlang: 1.5.2
python-libsbml: 5.19.0
networkx: 2.8.8
scipy: 1.10.1
scikit-learn: 0.23.1
matplotlib: 3.3.4
tqdm: 4.66.5
rdkit: 2022.3.5
node2vec: 0.4.6
openpyxl: 3.1.5
```

In addition, users are required to install the ```cplex``` solver (https://www.ibm.com/analytics/cplex-optimizer) from IBM to run the codes of gap-fillings. It is noted that cplex only works with certain python versions (e.g., CPLEX_Studio12.10 has APIs for python3.6 an python3.7).

## Usage
- We extracted metabolite features from metabolite SMILES and molecular structures using the pre-trained models ```ChemBERTa``` and ```GraphMVP```, respectively.
- The link to the pre-trained model ```ChemBERTa``` is as follows: https://huggingface.co/seyonec/ChemBERTa-zinc-base-v1
- The link to the pre-trained model ```GraphMVP``` is as follows: https://github.com/chao1224/GraphMVP
- If you wang to run ```HGLMA```, please download pre-trained node embedding files for all metabolites **`metabolite_emb_2816.pkl`** ([download link](https://drive.google.com/file/d/1-21en06Ds1Bo11ljRYP-1qelxAb91QJb/view?usp=sharing)) and place it in the `data` folder.
- To run the code, you need to navigate to the corresponding folder first, then type "python3 main.py" in your terminal.


### Prepare your input files

1. The folder ```HGLMA_gapfilling/BiGG Models``` contains 1 GEM from Zimmermann et al. as examples. GEM is a xml file.
2. The folder ```HGLMA_gapfilling/data/pools``` need to contain a reaction pool under name ```bigg_universe.xml```. Each pool is a GEM that has the extension ```.xml```. To use your own pool, remember to rename it to ```universe.xml```. Also remember to edit ```EX_SUFFIX``` and ```NAMESPACE``` in the input_parameters.txt to specify the suffix of exchange reactions and which namespace of biochemical reaction database is used. For ```NAMESPACE```, we currently only support ```bigg```.
